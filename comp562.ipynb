{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Set the kernel to use\n",
    "# # Replace 'tf' with the name of your kernel\n",
    "# import os\n",
    "# os.environ['JUPYTER_KERNEL_NAME'] = 'tf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stroke.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d057910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continuous = df[['age', 'avg_glucose_level', 'bmi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1da189",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_continuous.corr(), annot=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2dc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if column != 'stroke':\n",
    "        if df[column].dtype != 'O':\n",
    "            sns.displot(df[column], kde=False, bins=10)\n",
    "            plt.title(f'Distribution of {column}')\n",
    "            plt.show()\n",
    "        else:\n",
    "            sns.countplot(data=df, x=column)\n",
    "            plt.title(f'Count of {column}')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ed1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_other_gender = df[df['gender'] == 'Other'].shape[0]\n",
    "\n",
    "# Print the number of rows where the gender is 'Other'\n",
    "print(f'The number of rows where the gender is Other is {num_other_gender}')\n",
    "\n",
    "#remove gender = other \n",
    "df =df[df['gender'] != 'Other']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unknownsmoker = df[df['smoking_status'] == 'Unknown']\n",
    "stroke_counts_unknownsmoker = df_unknownsmoker['stroke'].value_counts()\n",
    "print(stroke_counts_unknownsmoker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of non-NaN values in the bmi column\n",
    "bmi_mean = df['bmi'].mean()\n",
    "print(bmi_mean)\n",
    "\n",
    "stroke_mean_bmi = df.loc[df['stroke'] == 1, 'bmi'].mean()\n",
    "print(stroke_mean_bmi)\n",
    "\n",
    "nonstroke_mean_bmi = df.loc[df['stroke'] == 0, 'bmi'].mean()\n",
    "print(nonstroke_mean_bmi)\n",
    "\n",
    "df.loc[(df['stroke'] == 1) & (df['bmi'].isnull()), 'bmi'] = stroke_mean_bmi\n",
    "df.loc[(df['stroke'] == 0) & (df['bmi'].isnull()), 'bmi'] = nonstroke_mean_bmi\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "# Fill the NaN values in the bmi column with the mean value\n",
    "#df['bmi'].fillna(bmi_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04474499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a pie chart of stroke values before removing unknown smokers\n",
    "stroke_counts = df['stroke'].value_counts()\n",
    "print(stroke_counts)\n",
    "plt.pie(stroke_counts, labels=['No Stroke', 'Stroke'], autopct='%1.1f%%')\n",
    "plt.title('Stroke Value Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566dda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unknown smokers\n",
    "print((df['smoking_status'] == 'Unknown').sum())\n",
    "df= df[df['smoking_status'] != 'Unknown']\n",
    "\n",
    "\n",
    "# Plot a pie chart of stroke values\n",
    "stroke_counts = df['stroke'].value_counts()\n",
    "plt.pie(stroke_counts, labels=['No Stroke', 'Stroke'], autopct='%1.1f%%')\n",
    "plt.title('Stroke Value Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crossing age and bmi due to moderate correlation to capture any interactions\n",
    "df['age_bmi'] = df['age'] * df['bmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56223ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b696b2a",
   "metadata": {},
   "source": [
    "## Chi-Squared Statistic\n",
    "We conduct the Pearson's Chi-Squared Statistic to test for independence between categorical variables. This is to conclude whether two variables (categorical and the target variable stroke) are related to each other. Null Hypothesis (H0): There is no relationship between the variables Alternative Hypothesis (H1): There is a statistically significant relationship between the variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "chi_table = pd.DataFrame(columns=[\"Category\", \"P-Value\",'Chi Square Test Stat', \"Conclusion\"])\n",
    "def find_dep(p_value): \n",
    "    alpha = 0.05\n",
    "    if p_value <= alpha: \n",
    "        return \"Dependent (reject H0)\"\n",
    "    else: \n",
    "        return \"Independent(Do not reject H0)\"\n",
    "## get the \n",
    "cat_variables = [\"gender\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\",\"Residence_type\",\"smoking_status\"]\n",
    "chi_lists = []\n",
    "\n",
    "for column in cat_variables:\n",
    "    contigency = pd.crosstab(df[column], df['stroke'])\n",
    "    stat, p_value, dof, expected = stats.chi2_contingency(contigency)\n",
    "    conclusion = find_dep(p_value)\n",
    "    each_col = [column, p_value, stat, conclusion]\n",
    "    chi_lists.append(each_col)\n",
    "\n",
    "for i in chi_lists:\n",
    "    chi_table.loc[len(chi_table)] = i\n",
    "chi_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf182336",
   "metadata": {},
   "source": [
    "## Point Biserial Correlation\n",
    "Point-biserial correlation is used to measure the relationship between a binary variable, x, and a continuous variable, y. We use this correlation strategy to see the level of correlation between the continuous variables and the target variable, stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "biser_table = pd.DataFrame(columns=[\"Category\", \"Biserial Stats\",'P_value', \"Conclusion\"])\n",
    "cont_var = [\"age\", \"bmi\", \"avg_glucose_level\", \"age_bmi\"]\n",
    "bi_lists = []\n",
    "for var in cont_var:\n",
    "   stat, p = stats.pointbiserialr(df[var], df[\"stroke\"])\n",
    "   each_val = [var, stat, p, find_dep(p)]\n",
    "   bi_lists.append(each_val)\n",
    "\n",
    "for i in bi_lists:\n",
    "    biser_table.loc[len(biser_table)] = i\n",
    "biser_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c5e08",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4398b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# encoder = OneHotEncoder()\n",
    "# one_hot = encoder.fit_transform(df[['gender','ever_married','work_type','Residence_type','smoking_status']])\n",
    "\n",
    "\n",
    "df = pd.get_dummies(df, columns = ['gender','ever_married','work_type','Residence_type','smoking_status']).astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c85ba5",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deed637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing standardization on continuous variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit the StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "df[['age', 'avg_glucose_level', 'bmi', 'age_bmi']] = scaler.fit_transform(df[['age', 'avg_glucose_level', 'bmi', 'age_bmi']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b13b7",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = df.select_dtypes(include=np.number).columns.tolist()\n",
    "tstats_df = pd.DataFrame()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for eachvariable in numeric:\n",
    "    tstats = stats.ttest_ind(df.loc[df[\"stroke\"] == 1, eachvariable], df.loc[df[\"stroke\"] == 0, eachvariable])\n",
    "    temp = pd.DataFrame([eachvariable, tstats[0], tstats[1]]).T\n",
    "    temp.columns = [\"Variable Name\", \"T stats\", \" P-value\"]\n",
    "    tstats_df = pd.concat([tstats_df, temp], axis = 0, ignore_index= True)\n",
    "tstats_df = tstats_df.sort_values(by=\" P-value\").reset_index(drop=True)\n",
    "print(tstats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5c139",
   "metadata": {},
   "source": [
    "At the 0.05 significant level, all the variables are statistically significant since the p-value < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import  pyplot\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26040c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(120)\n",
    "y_feature_selection = df['stroke'] # dependent variable\n",
    "x_feature_selection = df.drop(columns=[\"stroke\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_feature_selection, y_feature_selection, test_size=0.33, random_state=7)\n",
    "model = XGBClassifier()\n",
    "model.fit(x_feature_selection, y_feature_selection)\n",
    "# plot feature importance\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd23b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "# corr_matrix = df[num_cols].corr()\n",
    "# sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "# plt.show()\n",
    "\n",
    "#roughly choose variables to check correlation based on feature importance from  xgboost above\n",
    "variables_to_plot = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'age_bmi', 'gender_Female', 'gender_Male', 'smoking_status_formerly smoked', 'smoking_status_never smoked', 'smoking_status_smokes', 'Residence_type_Rural', 'Residence_type_Urban', 'stroke']\n",
    "corr_matrix2 = df[variables_to_plot].corr()\n",
    "\n",
    "#plot after scaling for more accurate correlation\n",
    "sns.heatmap(corr_matrix2, annot=True, cmap='coolwarm', annot_kws={\"fontsize\":6})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee58b9",
   "metadata": {},
   "source": [
    "# Removing Residence Type, Gender and BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d029b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing residence_type\n",
    "#to_drop = ['Residence_type','gender','bmi']\n",
    "to_drop = ['Residence_type_Rural', 'Residence_type_Urban', 'gender_Male', 'gender_Female', 'bmi']\n",
    "df2= df.drop(to_drop, axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49332c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=109)\n",
    "\n",
    "X_df2 = df2.drop('stroke', axis=1)\n",
    "y_df2 = df2['stroke']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_df2, y_df2, test_size=0.3, random_state=109)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c792d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import  pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without resampling (unbalanced dataset)\n",
    "\n",
    "# # Define model\n",
    "# xgb_model_unsampled = XGBClassifier()\n",
    "\n",
    "# # Train model\n",
    "# xgb_model_unsampled.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate model\n",
    "# y_pred_unsampled = xgb_model_unsampled.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred_unsampled)\n",
    "# f1 = f1_score(y_test, y_pred_unsampled)\n",
    "# precision = precision_score(y_test, y_pred_unsampled)\n",
    "# recall = recall_score(y_test, y_pred_unsampled)\n",
    "\n",
    "# print('Accuracy Unsampled: %.2f%%' % (accuracy * 100.0))\n",
    "# print('F1 Score Unsampled: %.2f%%' % (f1 * 100.0))\n",
    "# print('Precision Unsampled: %.2f%%' % (precision * 100.0))\n",
    "# print('Recall Unsampled: %.2f%%' % (recall * 100.0))\n",
    "\n",
    "#Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Perform grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Retrain model with best hyperparameters\n",
    "unsampled_best = XGBClassifier(**grid_search.best_params_)\n",
    "unsampled_best.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred_unsampled2 = unsampled_best.predict(X_test)\n",
    "\n",
    "accuracy2 = accuracy_score(y_test, y_pred_unsampled2)\n",
    "f12 = f1_score(y_test, y_pred_unsampled2)\n",
    "precision2 = precision_score(y_test, y_pred_unsampled2)\n",
    "recall2 = recall_score(y_test, y_pred_unsampled2)\n",
    "\n",
    "print('Accuracy with best hyperparameters: %.2f%%' % (accuracy2 * 100.0))\n",
    "print('F1 Score with best hyperparameters: %.2f%%' % (f12 * 100.0))\n",
    "print('Precision with best hyperparameters: %.2f%%' % (precision2 * 100.0))\n",
    "print('Recall with best hyperparameters: %.2f%%' % (recall2 * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after resampling\n",
    "from copy import deepcopy\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Instantiate SMOTE object\n",
    "smote = SMOTE(random_state = 42, sampling_strategy = 0.5)\n",
    "\n",
    "# Resample the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the number of samples in each class before and after resampling\n",
    "print(f\"Before resampling: \\n{y_train.value_counts()}\")\n",
    "print(f\"After resampling: \\n{y_resampled.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset after dropping selected columns\n",
    "from copy import deepcopy\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Instantiate SMOTE object\n",
    "smote = SMOTE(random_state = 42, sampling_strategy = 0.5)\n",
    "\n",
    "# Resample the data\n",
    "X_resampled2, y_resampled2 = smote.fit_resample(X_train2, y_train2)\n",
    "\n",
    "# Print the number of samples in each class before and after resampling\n",
    "print(f\"Before resampling: \\n{y_train2.value_counts()}\")\n",
    "print(f\"After resampling: \\n{y_resampled.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a369a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "def get_model_results(classifier, model, x_train, y_train, x_test, y_test):\n",
    "    # fit the model with data \n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Results for \"+ classifier)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test,y_pred))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test,y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test,y_pred))\n",
    "    print(\"F1 Score:\", metrics.f1_score(y_test,y_pred))\n",
    "\n",
    "    # confusion matrix \n",
    "    cfn_matrix = metrics.confusion_matrix(y_test,y_pred,labels=[1,0])\n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    print(cfn_matrix)\n",
    "\n",
    "    # Classification Report \n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "    recall = metrics.recall_score(y_test,y_pred)\n",
    "    precision = metrics.precision_score(y_test,y_pred)\n",
    "    f1 = metrics.f1_score(y_test,y_pred)\n",
    "    results = [accuracy, recall, precision, f1]\n",
    "\n",
    "    print(results)\n",
    "    # print the auc curve and show auc score \n",
    "    #plot roc curve \n",
    "    import matplotlib.pyplot as plt \n",
    "    # predicted probabilities of class 1 \n",
    "    by_pred_prob_model = model.predict_proba(x_test)[:,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, by_pred_prob_model)\n",
    "    auc = metrics.roc_auc_score(y_test, by_pred_prob_model)\n",
    "    plt.plot(fpr,tpr,label=\"XGB_Model, auc =\"+str(\"{:.3f}\".format(auc)))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random guessing')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    ab_auc = auc\n",
    "    print(\"AUC Score:\" , ab_auc)\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d94d4f",
   "metadata": {},
   "source": [
    "# XGBOOST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cc20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb model before dropping variables\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "#Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Perform grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring = 'f1')\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Retrain model with best hyperparameters\n",
    "xgb_best = XGBClassifier(**grid_search.best_params_)\n",
    "xgb_best.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred_xgb = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "xgb_f1 = f1_score(y_test, y_pred_xgb)\n",
    "xgb_precision = precision_score(y_test, y_pred_xgb)\n",
    "xgb_recall = recall_score(y_test, y_pred_xgb)\n",
    "\n",
    "print('Accuracy with best hyperparameters: %.2f%%' % (xgb_accuracy * 100.0))\n",
    "print('F1 Score with best hyperparameters: %.2f%%' % (xgb_f1 * 100.0))\n",
    "print('Precision with best hyperparameters: %.2f%%' % (xgb_precision * 100.0))\n",
    "print('Recall with best hyperparameters: %.2f%%' % (xgb_recall * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import xgboost as xgb\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_xgb2)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "# plt.plot(fpr, tpr, label='AUC = %0.2f' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random guessing')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "# confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# matrix = confusion_matrix(y_test, y_pred_xgb2)\n",
    "# print(matrix)\n",
    "\n",
    "get_model_results('XGB', xgb_best, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb model after dropping residence_type,bmi,gender\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "#Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Perform grid search to find best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_resampled2, y_resampled2)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Retrain model with best hyperparameters\n",
    "xgb_best2 = XGBClassifier(**grid_search.best_params_)\n",
    "xgb_best2.fit(X_resampled2, y_resampled2)\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred_xgb2 = xgb_best2.predict(X_test2)\n",
    "\n",
    "xgb_accuracy2 = accuracy_score(y_test2, y_pred_xgb2)\n",
    "xgb_f12 = f1_score(y_test2, y_pred_xgb2)\n",
    "xgb_precision2 = precision_score(y_test2, y_pred_xgb2)\n",
    "xgb_recall2 = recall_score(y_test2, y_pred_xgb2)\n",
    "\n",
    "print('Accuracy with best hyperparameterss: %.2f%%' % (xgb_accuracy2 * 100.0))\n",
    "print('F1 Score with best hyperparameters: %.2f%%' % (xgb_f12 * 100.0))\n",
    "print('Precision with best hyperparameters: %.2f%%' % (xgb_precision2 * 100.0))\n",
    "print('Recall with best hyperparameters: %.2f%%' % (xgb_recall2 * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cddf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate ROC curve and AUC\n",
    "# fpr2, tpr2, thresholds2 = roc_curve(y_test2, y_pred_best2)\n",
    "# roc_auc2 = auc(fpr2, tpr2)\n",
    "# print(roc_auc2)\n",
    "\n",
    "# # Plot ROC curve\n",
    "# plt.plot(fpr2, tpr2, label='AUC = %0.2f' % roc_auc2)\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random guessing')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "get_model_results('XGB', xgb_best2, X_resampled2, y_resampled2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e49a538",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning for svm1\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "n_estimators = 10\n",
    "\n",
    "param_grid = {\n",
    "    'base_estimator__C': [0.1,1, 10, 100, 1000], \n",
    "    'base_estimator__gamma': [1,0.1,0.01,0.001, 0.0001],\n",
    "    'base_estimator__kernel':  ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "\n",
    "svm = svm.SVC()\n",
    "\n",
    "bagging_svm = BaggingClassifier(svm, random_state = 88,max_samples=1.0 / n_estimators, n_estimators=n_estimators)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    bagging_svm,\n",
    "    param_grid=param_grid,\n",
    "    scoring = 'f1'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "print('Best hyper parameters:', grid_search.best_params_, 'Score', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9770757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm before dropping variables\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "svm1 = BaggingClassifier(svm.SVC(kernel=grid_search.best_params_['base_estimator__kernel'], gamma = grid_search.best_params_['base_estimator__gamma'], C = grid_search.best_params_['base_estimator__C'] ), random_state = 88,max_samples=1.0 / n_estimators, n_estimators=n_estimators )\n",
    "svm1.fit(X_resampled, y_resampled)\n",
    "y_pred_SVM = svm1.predict(X_test)\n",
    "get_model_results('SVM', svm1, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning for svm2\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "n_estimators = 10\n",
    "\n",
    "param_grid = {\n",
    "    'base_estimator__C': [0.1,1, 10, 100, 1000], \n",
    "    'base_estimator__gamma': [1,0.1,0.01,0.001, 0.0001],\n",
    "    'base_estimator__kernel':  ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "\n",
    "svm2 = svm.SVC()\n",
    "\n",
    "bagging_svm = BaggingClassifier(svm, random_state = 88,max_samples=1.0 / n_estimators, n_estimators=n_estimators)\n",
    "\n",
    "grid_search2 = GridSearchCV(\n",
    "    bagging_svm,\n",
    "    param_grid=param_grid,\n",
    "    scoring = 'f1'\n",
    ")\n",
    "\n",
    "grid_search2.fit(X_resampled2, y_resampled2)\n",
    "\n",
    "\n",
    "print('Best hyper parameters:', grid_search2.best_params_, 'Score', grid_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm after dropping variables\n",
    "from sklearn import svm\n",
    "\n",
    "svm2 = BaggingClassifier(svm.SVC(kernel=grid_search2.best_params_['base_estimator__kernel'], gamma = grid_search2.best_params_['base_estimator__gamma'], C = grid_search2.best_params_['base_estimator__C'] ), random_state = 88,max_samples=1.0 / n_estimators, n_estimators=n_estimators, )\n",
    "svm2.fit(X_resampled2, y_resampled2)\n",
    "y_pred_SVM2 = svm2.predict(X_test2)\n",
    "get_model_results('SVM with dropped columns', svm2, X_resampled2, y_resampled2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a376da",
   "metadata": {},
   "source": [
    "# LOG REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7dc6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5,scoring = 'f1')\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258572f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=10, penalty='l2')\n",
    "# Fit the logistic regression model to the entire training set\n",
    "logreg.fit(X_resampled, y_resampled)\n",
    "y_pred_logreg= logreg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_results(\"Logistic Regression \", logreg, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_resampled.columns\n",
    "coefficients = logreg.coef_[0]\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Feature Name', 'Coefficient']\n",
    "for feature, coef in zip(feature_names, coefficients):\n",
    "    table.add_row([feature, coef])\n",
    "\n",
    "# Print the table\n",
    "print(table)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_names, coefficients)\n",
    "plt.xticks(feature_names, rotation=45)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc8c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid2 = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "grid_search2 = GridSearchCV(LogisticRegression(), param_grid2, cv=5, scoring = 'f1')\n",
    "grid_search2.fit(X_resampled2, y_resampled2)\n",
    "best_params2 = grid_search2.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49923e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression(**best_params2)\n",
    "\n",
    "# Fit the logistic regression model to the entire training set\n",
    "logreg2.fit(X_resampled2, y_resampled2)\n",
    "y_pred_logreg2= logreg2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17366f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_results(\"Logistic Regression \", logreg2, X_resampled2, y_resampled2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332485c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names2 = X_resampled2.columns\n",
    "coefficients2 = logreg2.coef_[0]\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "table2 = PrettyTable()\n",
    "table2.field_names = ['Feature Name', 'Coefficient']\n",
    "for feature2, coef2 in zip(feature_names2, coefficients2):\n",
    "    table2.add_row([feature2, coef2])\n",
    "\n",
    "# Print the table\n",
    "print(table2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_names2, coefficients2)\n",
    "plt.xticks(feature_names2, rotation=45)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55c758",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import AdaBoost Model \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'n_estimators': [50,100,200,400],\n",
    "    'algorithm': ['SAMME','SAMME.R'],\n",
    "    'learning_rate': [0.001,0.05,0.1,0.2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692cd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abModel = AdaBoostClassifier(random_state=23)\n",
    "gridCV = GridSearchCV(abModel, param_grid=grid_params, verbose=False)\n",
    "gridCV.fit(X_resampled, y_resampled)\n",
    "print('Best hyper parameters:', gridCV.best_params_, 'Score', gridCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa89505",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_AB = AdaBoostClassifier(n_estimators = 400, learning_rate = 0.2, algorithm = 'SAMME.R', random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_results(\"Ada Boosting\", good_AB, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e718e384",
   "metadata": {},
   "source": [
    "# Ada Boost on dropped column dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'n_estimators': [50,100,200,400],\n",
    "    'algorithm': ['SAMME','SAMME.R'],\n",
    "    'learning_rate': [0.01,0.05,0.1,0.2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "abModel = AdaBoostClassifier(random_state=23)\n",
    "gridCV = GridSearchCV(abModel, param_grid=grid_params, verbose=False)\n",
    "gridCV.fit(X_resampled2, y_resampled2)\n",
    "print('Best hyper parameters:', gridCV.best_params_, 'Score', gridCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_dropped = AdaBoostClassifier(n_estimators = 400, learning_rate = 0.2, algorithm = 'SAMME.R', random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf516fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_results(\"Ada Boosting\", AB_dropped, X_resampled2, y_resampled2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0992e8b6",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdff60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as layers\n",
    "import keras.models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc819a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac43a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Dense(11, activation='relu', input_dim=20))\n",
    "    model.add(layers.Dense(7, activation='relu', input_dim=20))\n",
    "    model.add(layers.Dense(5, activation='relu', input_dim=20))\n",
    "    model.add(layers.Dense(1, activation='sigmoid', name='predictions'))\n",
    "    # return model without compile\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(109)\n",
    "\n",
    "# hyperparameter tuning\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, loss=\"binary_crossentropy\", verbose=False, optimizer = keras.optimizers.Adam(lr=1e-5))\n",
    "\n",
    "# define the grid search parameters\n",
    "epochs = [250, 500, 750, 1000]\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1')\n",
    "grid_result = grid.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938311fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print('Best hyper parameters:', grid.best_params_, 'Score', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea780fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Dense(11, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid', name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(lr=1e-5), \n",
    "              metrics=['accuracy',\n",
    "                       keras.metrics.Precision(name='precision'),\n",
    "                       keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_resampled, y_resampled, epochs=1000, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede28314",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = [\n",
    "    1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_results_nn(classifier, predictions, y_pred, y_test):\n",
    "    \n",
    "    print(\"Results for \"+ classifier)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test,y_pred))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test,y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test,y_pred))\n",
    "    print(\"F1 Score:\", metrics.f1_score(y_test,y_pred))\n",
    "\n",
    "    # confusion matrix \n",
    "    cfn_matrix = metrics.confusion_matrix(y_test,y_pred,labels=[1,0])\n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    print(cfn_matrix)\n",
    "\n",
    "    # Classification Report \n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "    recall = metrics.recall_score(y_test,y_pred)\n",
    "    precision = metrics.precision_score(y_test,y_pred)\n",
    "    f1 = metrics.f1_score(y_test,y_pred)\n",
    "    results = [accuracy, recall, precision, f1]\n",
    "\n",
    "    print(results)\n",
    "    # print the auc curve and show auc score \n",
    "    \n",
    "    # predicted probabilities of class 1 \n",
    "    by_pred_prob_model = predictions.ravel()\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, by_pred_prob_model)\n",
    "    auc = metrics.roc_auc_score(y_test, by_pred_prob_model)\n",
    "    \n",
    "    # plot roc curve \n",
    "    plt.plot(fpr, tpr, label='AUC = %0.2f' % auc)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random guessing')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10570dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "get_model_results_nn(\"Neural Network\", predictions, y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248ab51",
   "metadata": {},
   "source": [
    "## Dataset without Residence Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model2():\n",
    "    # create model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Dense(11, activation='relu', input_dim=15))\n",
    "    model.add(layers.Dense(7, activation='relu', input_dim=15))\n",
    "    model.add(layers.Dense(5, activation='relu', input_dim=15))\n",
    "    model.add(layers.Dense(1, activation='sigmoid', name='predictions'))\n",
    "    # return model without compile\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(109)\n",
    "\n",
    "# hyperparameter tuning\n",
    "# create model\n",
    "model2 = KerasClassifier(model=create_model2, loss=\"binary_crossentropy\", verbose=False, optimizer = keras.optimizers.Adam(lr=1e-5))\n",
    "\n",
    "epochs = [500, 1000]\n",
    "batch_size = [10, 40, 80]\n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "grid2 = GridSearchCV(estimator=model2, param_grid=param_grid, scoring='f1')\n",
    "grid_result2 = grid2.fit(X_resampled2, y_resampled2)\n",
    "\n",
    "# grid2 = GridSearchCV(estimator=model2, param_grid=param_grid, scoring='f1')\n",
    "# grid_result2 = grid2.fit(X_resampled2, y_resampled2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print('Best hyper parameters:', grid2.best_params_, 'Score', grid2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential()\n",
    "model2.add(layers.Dense(11, activation='relu'))\n",
    "model2.add(layers.Dense(7, activation='relu'))\n",
    "model2.add(layers.Dense(5, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid', name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e697f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "               optimizer=keras.optimizers.Adam(lr=1e-5), \n",
    "               metrics=['accuracy',\n",
    "                        keras.metrics.Precision(name='precision'),\n",
    "                        keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bba16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with data \n",
    "model2.fit(X_resampled2, y_resampled2, epochs=1000, batch_size=20)\n",
    "\n",
    "predictions2 = model2.predict(X_test2)\n",
    "y_pred2 = [\n",
    "    1 if prob > 0.5 else 0 for prob in np.ravel(predictions2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90248ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "get_model_results_nn(\"Neural Network 2\", predictions2, y_pred2, y_test2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed64e887c0db85af0f609450916873e94a5ac4573b8ce02a48545e4670322aa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
